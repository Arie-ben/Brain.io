{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_url_valid(url):\n",
    "    if url[:4] != \"http\":\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "def domain_without_www(domain):\n",
    "    if domain[:4] == \"www.\":\n",
    "        return domain[4:]\n",
    "    return domain\n",
    "\n",
    "\n",
    "def filter_rows(df):\n",
    "    df['is_valid'] = df.url.apply(is_url_valid)\n",
    "    df = df[df['is_valid'] == True]\n",
    "    df = df.drop(['is_valid'], axis=1)\n",
    "    df['domain'] = df.domain.apply(domain_without_www)\n",
    "    df = df.dropna()\n",
    "    df = df.sort_values('visit_time_ms', ascending=False)\n",
    "    return df.reset_index().drop('index', axis=1)\n",
    "\n",
    "\n",
    "def fuck_of_this_domain(df, domains):\n",
    "    for domain in domains:\n",
    "        df = df.loc[df['domain'] != domain]\n",
    "    return df.reset_index().drop('index', axis=1)\n",
    "    \n",
    "\n",
    "def clean_date(df):   \n",
    "    df.day = [re.sub('[-:]', '/', df.day[i]) for i in range(len(df))]\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            df.day[i] = pd.to_datetime(df.day[i] + '-'+ df.time[i])\n",
    "        except ValueError:\n",
    "            df.day[i] = None\n",
    "    return filter_rows(df.drop('time', axis=1))\n",
    "\n",
    "\n",
    "def find_indexes(df, url):\n",
    "    return df.loc[df['url'] ==  url].index.tolist()\n",
    "\n",
    "\n",
    "def replace_same_url(df, url, indexes):\n",
    "    index = 0\n",
    "    while index < len(indexes):\n",
    "        if df.url[indexes[index]] == url:\n",
    "            indexes.pop(index)\n",
    "            last_i = indexes[-1] + 1\n",
    "            while df.url[last_i] == url and last_i != df.index.max():\n",
    "                last_i += 1\n",
    "            indexes += [last_i]\n",
    "        else:\n",
    "            index += 1\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def weighted_urls(df, url, previous_url, NUM_OF_NEXT=5, NUM_OF_PREVIOUS=2):\n",
    "    indexes_after = [range(element - NUM_OF_NEXT, element) for element in find_indexes(df, url) if element - NUM_OF_NEXT > 0]\n",
    "    for index in range(len(indexes_after)):\n",
    "        indexes_after[index] = replace_same_url(df, url, indexes_after[index])\n",
    "    indexes_before = [range(element + 1, element + 1 + NUM_OF_PREVIOUS) for element in find_indexes(df, url)]\n",
    "    if indexes_after:\n",
    "        if indexes_after[0] == []:\n",
    "            indexes_after.pop(0)\n",
    "\n",
    "    weights = [float(1)/2**i for i in range(NUM_OF_NEXT)]\n",
    "    urls_before = [df.url[i].values  for i in indexes_before]\n",
    "    urls_after = [df.url[i].values  for i in indexes_after]\n",
    "    urls_weighted = []\n",
    "\n",
    "    for j in range(len(urls_after)):\n",
    "        weights = [float(1)/2**(NUM_OF_NEXT - i -1) for i in range(NUM_OF_NEXT)]\n",
    "        coef = 1\n",
    "        i = 0\n",
    "        while i < NUM_OF_PREVIOUS and previous_url[i] == urls_before[j][i]:\n",
    "            weights = [weight*2 for weight in weights]\n",
    "            i += 1\n",
    "        urls_weighted.append([(urls_after[j][k], weights[k]) for k in range(len(weights))])            \n",
    "    return urls_weighted\n",
    "\n",
    "\n",
    "def get_weigths(df, url, previous_url):\n",
    "    \n",
    "    weigth_dic = {}\n",
    "    for url_list in weighted_urls(df, url, previous_url):\n",
    "        for url in url_list:\n",
    "            if url[0] in weigth_dic:\n",
    "                weigth_dic[url[0]] += url[1]\n",
    "            else:\n",
    "                weigth_dic[url[0]] = url[1]\n",
    "\n",
    "    return sorted(weigth_dic.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "\n",
    "def is_in_time(df, index, threshold):\n",
    "    if df.day[index-1] - df.day[index] < pd.Timedelta(threshold, 's') :\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_int(number):\n",
    "    if not isinstance(number, float) and \",\" in number:\n",
    "        number = number.replace(\",\", \".\")\n",
    "    return float(number)\n",
    "\n",
    "\n",
    "def delta(df):\n",
    "    df.visit_time_ms = df.visit_time_ms.apply(to_int)\n",
    "    df = df.sort_values('visit_time_ms', ascending = False)\n",
    "    df['delta'] = [df.visit_time_ms[index] - df.visit_time_ms[index + 1] for index in range(df.shape[0] - 1)] + [0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def treat_data(df_path, filtered_domains):\n",
    "    df = pd.read_csv(df_path, delimiter=\";\", header=None)\n",
    "    df.columns = (['url', 'domain', 'root domain', 'visit_time_ms', 'visit_time_str', 'day of the week', 'transition_type', 'page title'])\n",
    "    df = df[['url', 'domain', 'visit_time_ms', 'visit_time_str', 'transition_type']]\n",
    "    df = filter_rows(df)\n",
    "    df = fuck_of_this_domain(df, filtered_domains)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_other_databases(folder_path, filtered_domains):\n",
    "    df_list = []\n",
    "    for df in os.listdir(folder_path):\n",
    "        if os.path.basename(df)[0] != \".\":\n",
    "            df_list.append(treat_data(folder_path + os.path.basename(df), filtered_domains))\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_domains = (['whatsapp.com','web.whatsapp.com', 'twitter.com', 'linkedin.com',\n",
    "                     'google.co.il','fr-fr.messenger.com','youtube.com','facebook.com', 'localhost',\n",
    "                     'plus.google.com','google.fr', 'mail.google.com', 'google.com','messenger.com',\n",
    "                     'listenonrepeat.com', 'drive.google.com', 'docs.google.com', 'calendar.google.com',\n",
    "                     'chrome.google.com', 'gmail.com', 'lefigaro.fr'])\n",
    "df_path = 'databases/antho_secrets.csv'\n",
    "folder_path = 'databases/other_databases/'\n",
    "df = treat_data(df_path, filtered_domains)\n",
    "df_list = get_other_databases(folder_path, filtered_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg2, arg3 = 'https://en.wikipedia.org/wiki/Naive_Bayes_classifier', [ \"\", \"\"]\n",
    "\n",
    "\n",
    "def sum_score(df_list, arg2, arg3):\n",
    "    score_dic = {}\n",
    "    for dataframe in df_list:\n",
    "        for i in get_weigths(dataframe, arg2, arg3):\n",
    "            if i[0] in score_dic:\n",
    "                score_dic[i[0]] += i[1]\n",
    "            else:\n",
    "                score_dic[i[0]] = i[1]\n",
    "\n",
    "    return sorted(score_dic.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "score_dic = sum_score(df_list, arg2, arg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://docs.python.org/3/library/datetime.html', 1.75), ('https://docs.python.org/3/tutorial/datastructures.html', 1.5), ('http://stackoverflow.com/questions/16151402/python-how-can-i-check-whether-an-object-is-of-type-datetime-date', 1.1875), ('https://www.surveymonkey.co.uk/r/VC99CZ5', 1.0), ('http://stackoverflow.com/questions/9504356/convert-string-into-date-type-on-python', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "print score_dic[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('http://hive.itcapp.com/', 7)\n",
      "('https://github.com/', 6)\n",
      "('https://israeltechallenge.com/', 6)\n",
      "('https://trello.com/', 5)\n",
      "('http://hive.itcapp.com/#', 5)\n",
      "('https://outlook.live.com/owa/?path=/mail/inbox', 5)\n",
      "('http://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe', 5)\n",
      "('http://hive.itcapp.com/login/?next=/', 5)\n",
      "('http://hive.itcapp.com/course/status?subject=C', 5)\n",
      "('https://outlook.live.com/owa/', 5)\n"
     ]
    }
   ],
   "source": [
    "list_set = [set(df.url.values)]\n",
    "for dataframe in df_list:\n",
    "    list_set.append(list(set(dataframe.url.values)))\n",
    "a = [item for sublist in list_set for item in sublist]\n",
    "b = Counter(a)\n",
    "for i in b.most_common()[:10]:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results_yourself(df_yourself, current_url, previous_urls):\n",
    "    best_recommandations = [i[0] for i in get_weigths(df_yourself, current_url, previous_urls)]\n",
    "    return best_recommandations[:5]\n",
    "\n",
    "\n",
    "def get_results_others(df_list, current_url, previous_urls):\n",
    "    best_recommandations = [i[0] for i in sum_score(df_list, arg2, arg3)]\n",
    "    return best_recommandations[:5]\n",
    "\n",
    "def split_website_videos(results):\n",
    "    websites = []\n",
    "    videos = []\n",
    "    for result in results:\n",
    "        if re.search(r\"^https://www.youtube.com/watch\", result):\n",
    "            videos.append(result)\n",
    "        else:\n",
    "            websites.append(result)\n",
    "    return websites, videos\n",
    "\n",
    "def interface_front_end(df_yourself, current_url, previous_urls, others=\"Results/others.txt\", yourself=\"Results/yourself.txt\", youtube=\"Results/youtube.txt\"):\n",
    "    \n",
    "    websites, videos = split_website_videos(get_results_others(df_list, current_url, previous_urls))\n",
    "    \n",
    "    file = open(others, \"w\")\n",
    "    results_others = []\n",
    "    for url in websites:\n",
    "        file.write(url)\n",
    "        file.write(os.linesep)\n",
    "    file.close()\n",
    "\n",
    "    file = open(yourself, \"w\")\n",
    "    for url in get_results_yourself(df_yourself, current_url, previous_urls):\n",
    "        file.write(url)\n",
    "        file.write(os.linesep)\n",
    "    file.close()\n",
    "\n",
    "    results_youtube = []\n",
    "    file = open(youtube, \"w\")\n",
    "    for url in videos:\n",
    "        file.write(url)\n",
    "        file.write(os.linesep)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "others = \"Results/others.txt\"\n",
    "yourself = \"Results/yourself.txt\"\n",
    "youtube = \"Results/youtube.txt\"\n",
    "\n",
    "arg2 = 'http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html'\n",
    "arg3 = [ \"\", \"\"]\n",
    "\n",
    "interface_front_end(df, arg2, arg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
